# 游戏客户端八股文

## C++相关

### 如何优化大量创建对象的开销
使用对象池，并且在销毁时并不直接销毁而是返回到对象池等待下一次使用，此时就能应对短时间内大量对象的创建所造成的性能压力，缺点就是存在暂时没有使用上的对象占用着内存。

### 多态与虚函数
1. 什么是多态
    多态是面相对象编程的一个核心概念，指的是对象(通过其引用和指针)可以表现出除它们自身类型以外的形式。多态的目的主要是允许一个接口表示不同的底层数据类型。**这样程序可以在运行时选择正确的方法而不是在编译时决定。**

2. 静态多态和动态多态
    * 静态多态(编译时多态): 主要通过函数重载和运算符重载实现。静态多态会在编译期间确定使用哪个一函数或者运算符。
    * 动态多态(运行时多态): 通过虚函数和继承方法实现，在运行时决定使用哪一个函数，依赖与对象的实际类型。

3. C++动态多态的实现
    C++中多态的实现主要通过虚函数，其中设计到两个非常重要的概念：虚函数表、虚函数指针
    * 虚函数表：
        定义：虚函数表是用于存放成员函数指针的数组，每个含有虚函数的类都有一个对应的虚函数表
        作用：当类的对象调用虚函数时，C++ runtime 会通过虚函数表来查找到需要调用的函数。这允许在运行时进行方法的绑定
        位置：虚函数表通常只存在与程序的**只读数据段(如全局数据段)**，而不是每一个对象的实例中。每一个类只有有一个虚函数表，多有对象共用一个表
        大小：虚函数表所占用的空间大小与虚函数的数量有关，等于`虚函数数量 * 函数指针大小(取决于操作系统)`

    * 虚函数指针：
        定义：虚函数指针是指向虚函数表的一个指针
        作用：每一个含有虚函数的类的对象都会包含一个这样的指针，用于指向响应的虚函数表
        位置：虚函数指针通常存储在对象的内存布局的开始位置(取决于不同编译器的实现)。
        大小：与普通的指针一致，取决于操作系统，如果操作系统是32位的，那么这个虚函数指针就是4字节，64位的操作系统下就是8字节

4. 构造函数可以是虚函数吗？
    C++中构造函数不能是虚函数，主要的原因有3点：
    * C++对象实例化的机制：由于虚函数的机制是在对象的**生命周期内部**进行工作的，而构造函数是用于创建对象实例的。因此在我们调用构造函数的时候，虚函数指针可能还没有被初始化完毕。
    * 构造函数的工作方式与虚函数不符合：当我们调用派生类的构造函数时，构造函数的执行顺序通常是先执行基类的构造函数，再执行派生类的，如果构造函数是虚函数，那么可能在调用基类构造函数的过程中直接调用了派生类的构造函数而造成基类某些成员变量没有完成初始化操作。从而导致程序错误

5. 析构函数可以是虚函数吗？
    C++的析构函数可以使虚函数，并且在类中存在动态资源和被继承的情况下，理应把析构函数设置成虚函数，否则可能会导致通过基类指针进行对象析构的过程中无法正常释放存在于派生类中的动态资源。当然，这个问题可以通过将所有的动态资源都是用智能指针进行管理来解决，此时，即使我们的析构函数不是虚函数，所有的资源也都能被正确的释放。

### 智能指针
C++的智能指针主要是提供了自动的动态内存资源管理，使程序员免于手动释放内存的困扰。
在C++中智能指针主要有3种：
1. `std::unique_ptr`
    std::unique_ptr提供了对动态分配的内存资源的唯一所有权，确保了同一时间内只有一个std::unique_ptr可以拥有该资源。
    * 这种唯一性是如何保证的呢？
        在unique_ptr中，其复制构造函数与赋值运算符都被禁用，从而保证了所管理对象的唯一性，但我们仍可以通过std::move来移交资源的所有权。
2. `std::shared_ptr`
    std::shared_ptr提供了多个指针共享一个对象的所有权，当最后一个指向这个资源的shared_ptr被销毁时释放。
    * 如何实现？
        std::shared_ptr通过维护一个引用计数器来实现共享所有全。每当一个新的shared_ptr指向同一个对象时，计数增加，反之，当shared_ptr销毁时，计数减少。
        * 当一个shared_ptr被销毁时是如何通知别的shared_ptr进行引用计数减少的呢？
            实际上引用计数不是被shared_ptr所拥有的，而是通过内部存在的一个控制快记录，这个控制块跟踪了有多少个shared_ptr实例在共享同一个资源，当一个shared_ptr被销毁的时候，其析构函数会被调用，这个析构函数负责将对应的控制快的引用次数减1。
            随后，在这个析构函数中，会检查引用计数是否已经降到0，若是为0，此时就会触发资源的回收。
    * 潜在问题
        * 循环引用问题：当使用具有父子关系的对象时，如果两个对象互相持有对方的shared_ptr，他们的引用计数就永远不会到0，导致内存泄露。
        * 性能开销问题：由于shared_ptr需要额外维护引用计数器，并且这个引用计数器是线程安全的，这意味着每一次的shared_ptr复制和销毁都需要进行原子操作，对于单线程而言可能影响不是很大，增加的操作只有引用计数的变化，但对于多线程程序来说，这意味着会导致整个程序的短暂停顿。
        * 线程安全问题：shared_ptr本身的操作是线程安全的，但是不能保证所指向的对象的操作一定是安全的。
3. `std::weak_ptr`
    std::weak_ptr被设计出来用于观察shared_ptr所管理的资源，主要目的就是解决shared_ptr的循环引用问题。weak_ptr不会影响其观察的对象的生命周期。
    * 工作原理
        * 在shared_ptr中我们提到了一个控制块，实际上这个控制块是weak_ptr和shared_ptr共享的，这个控制块是既包含了用于shared_ptr资源的引用计数以及用于weak_ptr的弱引用计数。

### C++编译过程
C++的编译主要有以下的四个步骤，分别是：预处理、编译、汇编、链接
1. 预处理
    在这一步主要处理以“#”号为开头的指令，包括对#define的宏的展开，#include的文件的插入，#if等指令的处理。
2. 编译
    在这一步中，会将上面处理好的cpp文件进行编译生成对应的汇编代码，在这个过程中包括了cpp的语法分析，语义分析以及进行各种优化。这些优化就包括去除冗余、循环展开等技术。
3. 汇编
    在这一步会将上一步生成的汇编代码转换为机器代码，生成目标文件，如`.o`或者`.obj`等。
4. 链接
    最后就是使用链接器将一个或多个目标文件与库文件链接起来，最终生成可执行文件。

### 静态库和动态库的区别

### C++函数调用的过程
C++的函数调用大致可以分为5个步骤
1. 参数准备
    当调用一个函数时，首先需要准备参数，通常来说这些参数对被**从右到左**存入栈中，或者是放入寄存器当中。这一步具体取决于编译器的实现。
2. 栈帧设置
    每一次函数进行调用的时候，都会在栈上创建一个栈帧。栈帧包含了函数的局部变量、用于存储寄存器的空间、返回地址等。通常而言在汇编中返回地址时使用%eax寄存器保存的，当然这取决于具体的计算机架构。
3. 函数体执行
    一旦栈帧设置完毕，程序计数器(PC)被设置为了函数体的起始位置时，开始执行函数中的代码。
4. 返回值计算
    执行完函数体后，通过跳转到栈帧中保存的返回地址来实现。
5. 栈帧清理
    函数执行完成后，需要清理为这个函数调用所创建的栈帧，栈指针(SP)和基指针(BP)会被恢复到函数调用前的状态
6. 控制权返回
    控制权返回到函数调用的下一条指令。

### C++STL
1. vector
    vector是STL标准模版库的一个容器，用于顺序、动态地存储元素。vector类的实现基于数组，在他的源码中，是通过保存一个指针实现的。
    vector的主要特征包括：动态大小、连续存储、随机访问、灵活性
    其中对于动态大小这个特点来说，当我们尝试给一个size==capacity的vector插入一个新元素时，vector类会自动的进行扩容。当我们插入元素不会触发vector扩容是，插入的时间复杂度为O(1)，当产生扩容的需求时，插入的时间复杂度为O(n)，由vector的扩容机制所决定，整体的插入时间复杂度为O(1)
    对于连续存储这个特点，这是因为vector的底层实现实际上就是使用一个指针指向一段连续的内存空间，所有保存在这个vector中的元素都会被存放在这个连续的空间中。因此，在顺序访问的情况下，vector的缓存性能很好。
    对于随机访问这个特点，同样是来自于vector对于数据存储的底层实现带来的特点，，因为使用的是一段连续的内存空间，因此我们可以通过使用index计算便宜量直接计算出我们需要访问的内存地址，这个计算的过程并不会收到vector长度的影响，因此他的时间复杂度是O(1)

    * vector的扩容过程
        1. 触发：当我们尝试给一个size==capacity的vector插入一个新元素时，vector类就会触发扩容
        2. 新容量计算：在进行扩容前，需要计算目标扩容的大小，这个大小通常是原vector的1.5到2倍，具体看不同的实现，这种增长策略目的是平衡内存使用和重新分配的次数，因为每次重新分配的时间复杂度为O(n)，通过指数级的增长我们可以减少重新分配的次数
        3. 分配新内存：紧接着是根据计算出来的新容量分配新的内存
        4. 元素迁移：完成内存分配后进行元素的迁移，将所有保存在原内存空间的数据全部重新迁移到新内存空间。在这个过程中，若是元素支持移动语意，则会调用其移动构造函数，否则通过拷贝构造函数。(这一步是造成扩容时间复杂度为O(n)的主要原因)
        5. 释放旧内存：一旦元素完成迁移，原来的内存将被释放
        6. 更新内部状态：完成内存释放后，会进行内部数据的更新，比如capacity的值，会更新为新分配的内存空间的大小

        从性能考虑上，我们在清楚某个vector将要存放多少数据的时候，尽可能使用reserve函数预分配好足够的空间，避免在不断的push_back的过程中进行扩容。

    * vector分配新内存是使用new还是malloc
        实际上在vector扩容的过程中使用的既不是new也不是malloc，而是使用标准分配器std::allocator实现的，在这个分配器的实现中，通常使用`::operator new`来分配内存，这个`::operator new`与我们平时使用的new不同，它所做的仅仅只是分配内存空间但不会初始化。
        那么为什么不直接使用malloc呢？这是因为在C++中，对象的生命周期非常重要，使用malloc可能会导致对象没有被正确的初始化。并且`::operator new`可以被重载，提供更灵活的内存策略

2. list
    list是STL标准模版酷的一个容器，实现了一个双向链表，允许程序员在序列的任一位置进行快速的插入和删除，但不同于vector，list并不支持随机访问，因为其实现是链表。
    list的主要特征包括：动态大小、双向遍历、内存分配上不同
    对于动态大小这个特点，std::list的大小可以根据需要动态的进行增加或减少，并且在增加过程中并不存在vector类中的扩容的现象。
    对于双向遍历这个特点，是由list容器的底层实现所提供的，双向链表会维护这个链表的头尾指针，我们可以通过头指针从前往后遍历，也能通过尾指针从后往前遍历。
    对于内存分配上的特点，同样是由list容器的底层实现是链表决定的，这决定了list容器中每一个元素之间不存在物理上连续的关系，仅仅只做到了逻辑上的连续。并且由于是链表，其缓存性能很差，基本上每一次访问下一个元素都会导致cache miss，不利于进行高性能的代码的编写。

    从性能方面考虑：
    list在任何位置的插入和删除操作的时间复杂度为O(1)，但寻找到需要进行插入和删除的位置的时间复杂度为O(n)
    在顺序访问方面，由于是链表，其缓存性能很差，基本上每一次访问下一个元素都会导致cache miss，不利于进行高性能的代码的编写。

3. deque
    TODO：
    std::deque是C++标准模板库中的一个序列容器，允许使用者在序列的前端和后端进行高效的元素插入和删除，同时提供随机访问。
    * deque的实现：
    * 

4. map
    std::map是C++中提供键值对存储的容器，存储的是唯一的键对应唯一的值的情况。
    map的底层是通过红黑树实现的，这种数据结构帮助map容器能保证在动态插入后能维持查询的高性能而不是像最简单的二叉搜索树一样可能会失去平衡。

    * 从性能方面考虑：
        map的插入、删除和查找操作，时间复杂度均为O(logn)
        同样的，树型数据结构的缺点就是缓存性能很差，因为每一个节点都是新分配的空间，我们不能保证其在物理上连续，因此如果是需要反复进行遍历的数据而言，使用vector要优于map。

    * 从内存效率方面考虑：
        由于map是树状结构，每一个节点需要保存子节点的指针，因此每一个节点都会比单纯的数据要更大

    * 与unordered_map的比较：
        由于底层实现是红黑树，因此对于需要保持键的有序性的情况在，使用map优于unordered_map，因为unordered_map的实现原理是hash，并不保证元素的存放是有序的。但是我们若是不要求有序，则unordered_map能提供更高的查询性能，通常为O(1)

    对于map的键是自定义类的时候，需要注意的是我们需要重载`operator<`符号保证std::map能对我们的自定义类键进行排序插入到红黑树中。

5. unordered_map
    std::unordered_map是C++中提供键值对存储的容器，存储的是唯一的键对应唯一的值的情况，与std::map类似，但底层实现不同
    unordered_map的底层实现是通过hash进行计算的，通过使用hash函数计算得到的index将元素保存到指定位置的桶中，**桶在unordered_map中的定义是存在hash冲突的键所存放的数据结构，通常由链表或者数组实现(C++的unordered_map是用链表来实现的)**。
    * 从性能上分析：
        理想情况在unordered_map的插入、删除和查找的时间复杂度为O(1)，但如果我们的hash函数选择的不好，无法很好的解决hash冲突的问题是，时间复杂度有可能会退化到O(n)

    * 从内存效率方面分析：
        相比起map而言，如果我们的hash函数选择的好，unordered_map可能可以更高效的使用内存，因为不需要保存如子节点指针等额外信息。

    * unordered_map的桶扩容过程
        当unordered_map中的size==bucket_size的时候(也可以说负载因子为1.0)，就会触发unordered_map的桶扩容，通过桶扩容达到缓解hash冲突的问题。
        1. 创建新的哈希表：扩容时，会创建一个新的哈希表，这个新的哈希表桶的数量通常是原来的两倍。有助于分散原来冲突的元素，减少碰撞
        2. 重新计算hash：对于原哈希表中的所有元素，重新根据现在的桶大小计算哈希，然后存入对应的位置。
        3. 释放旧的哈希表：完整所有元素的哈希重新计算与存入后，释放旧的哈希表。

        桶的扩容与vector类似，都是非常消耗性能的操作，时间复杂度是O(n)，并且在扩容过程中会短暂的提高内存占用。因此，在了解我们需要一次性插入的数据的数量时，提前调用`reserve`函数进行提前分配空间从而避免过多的扩容操作。

    * 与map的比较：
        与map相比，unordered_map不能保证元素的有序性，但因此提高了增删查的性能，具体需要通过使用场景判断使用哪一个容器更合适

    对于unordered_map的键是自定义类的时候，我们需要重载`operator==`符号来保证查询过程中能进行相等比较，同时我们需要重载`std::hash<T>`模板的特化提供自定义的hash函数，帮助插入、删除和查询。

6. set
    与map类似，但是存的值是单个元素而非键值对。
    set同样能保证数据的有序性，并且还包括一个去重的特点

7. unordered_set
    与unordered_map类似，但是存的值是单个元素而非键值对。
    unordered_set不能保证数据的有序性，但仍保留数据去重的特性

8. queue

9. stack

### C++多线程

### C++ Lambda表达式

### static和const关键字
1. static的用法
    1. static关键字在类成员中的用法
        * 可以通过static关键字声明静态成员变量，这个静态成员变量会在程序执行main函数前进行初始化，并且其不属于任何一个对象，而是属于这个类本身
        * 可以通过static关键字声明静态成员函数，静态成员函数可以让我们在没有类对象实例的情况下进行调用，需要注意的是，静态成员函数中不能使用非静态成员变量，但可以使用静态的成员变量。
    2. static关键字在函数作用域中的用法
        * 我们可以通过在函数作用域中升级一个静态的变量，这个变量会在第一次调用这个函数时初始化，并程序执行的剩余时间里一直保持存在，直到程序执行结束
    3. static关键字在文件作用域上的用法
        * static关键字作用于全局变量和普通的函数时，可以将其的可见性限制在当前的文件内，使得其他的文件无法使用extern等方法访问。

2. const关键字的用法
    * 当const关键字作用于变量的时候，可以用于声明一个常量，这个常量在第一次初始化后便不能再修改。
    * 当const关键字作用域指针的时候，其作用取决于const相对于星号的位置，当const位于星号的左侧时，即`const int *`，这时，我们指针指向的值不能被改变，但是我们能改变这个指针的指向；当const位于星号的右侧时，即`int* const`，这时，我们的指针不能被改变，但是指针指向的值我们可以修改。
    * 当const作用于类成员函数时，表示这个成员函数不会修改这个类的状态，比如如果想要在一个const成员函数中修改一个成员变量时，编译器会报错，告诉我们不能这么做。

### new/malloc的区别
1. 从语言层面上来说，malloc是C语言的一个函数，而new是C++语言中的操作符。
2. 从内存初始化层面上来说，malloc函数的作用仅仅只有分配内存空间而不会初始化，但new操作符不仅会分配空间，还会调用对象的构造函数进行初始化，如果类型为基本数据类型时，则会初始化为默认值。
3. 从返回类型上来讲，malloc函数返回的是`void*`类型的指针，而new操作符会根据数据类型自动初始化，不需要程序员手动进行指针类型的转换。
4. 从错误处理上来讲，malloc过程中若是发生错误，则会返回NULL，而new操作符会抛出std::bad_alloc异常，除非我们使用了nothrow版本的new操作符，此时若是发生错误，则会返回NULL，就像malloc一样
5. 从使用角度上来讲，malloc需要程序员使用sizeof运算符手动计算需要分配的内存空间大小，而new操作符会自动计算所需的空间大小。
6. 从内存对齐方面，new操作符通常保证了更好的内存对齐，在C++中编译器知道每种类型的内存对齐要求，因为我们通常是以new Type的形式进行内存分配。但是malloc函数的使用过程中我们并没有指定我们想要的类型，因此malloc函数并不清楚我们所想创建的类型的内存对齐信息。

### C++内存分布
主要来说C++的内存分布可以被分为5个部分，分别是：堆、栈、静态/全局存储区、常量存储区、代码区
1. 堆
    C++的堆主要用于分配内存，通常通过操作如`new`和`delete`或者C语言中的`malloc`和`free`进行操控。
    * 如何禁止一个类的对象在堆中分配
        要实现这个非常简单，我们只需要在这个类中将new和delete操作符设置为私有，或将其定义为delete，此时当我们就无法使用new和delete在堆中创建这个对象。代码如下：
        ```cpp
        class NoHeapAlloc {
        private:
            // 重载new和delete操作符并设置为私有，阻止在堆上分配
            void* operator new(size_t size) = delete;
            void operator delete(void* pointer) = delete;

        public:
            NoHeapAlloc() {}  // 构造函数
            ~NoHeapAlloc() {} // 析构函数
        };
        ```

2. 栈
    C++的栈主要用于存储直接声明的变量，比如`int a = 0;`此时这个a变量就存储在栈中。这些变量由程序自动创建和销毁，不需要程序员的介入。
    一般来说，栈的内存分配和回收都很快，因为他是线性和连续的，通常是用于存储函数参数和局部变量。
    * 如何禁止一个类的对象在栈上进行分配？
        我们可以通过将所有的构造函数和析构函数设置为私有，并且暴露一些静态函数用于不同情况下的通过new操作符进行创建类对象，以及相应的destroy函数用于销毁对象。代码如下：
        ```cpp
        class NoStackAlloc {
        private:
            NoStackAlloc() {}  // 私有构造函数
            ~NoStackAlloc() {} // 私有析构函数

        public:
            static NoStackAlloc* CreateInstance() {
                return new NoStackAlloc();
            }

            static void DestroyInstance(NoStackAlloc* instance) {
                delete instance;
            }
        };
        ```

3. 全局/静态存储区
    顾名思义，这部分就是用来存储全局变量和静态变量的区域，存储在这部分里的变量会在程序开始时进行空间的分配(Lazy static变量除外)，直到程序结束时才会销毁。
4. 常量存储区
    顾名思义，常亮存储区就是用来存储常量的，比如字符串字面量和用const关键字声明的变量。这部分内存通常是只读的。
5. 代码段
    这部分内存用于存储这个程序在边以后的代码，用来告诉计算机这个程序该怎么运行，这部分也是只读的。

### 菱形继承类的内存布局


### 指针和引用的区别
1. 指针
    指针本质上就是一个存储在栈中的变量(局部中声明的指针，若是在全局范围内声明的指针则是存储与全局/静态存储区中)，只不过它的用途是用来存储一段地址，这个地址指向的就是真正的数据。

2. 引用
    引用的本质就是一个变量的一个别名，他是已经存在的一个变量的另一个名字

3. 区别
    * 他们的空值不同：指针允许有空值，就是常用的nullptr，但是引用不能存在空值，他一定是某一个已经存在的变量的另一个名称。这也说明了通常使用引用是更加安全的，因为引用保证了永远有一个被引用的对象存在，但是指针不一定。
    * 内存占用上也不同：指针通常会占用4到8字节的内存空间，这与程序运行的操作系统有关，32位的操作系统下指针就是4个字节，64位就是8个。但是引用通常不会占用内存空间（这取决于不同编译器的实现）。
    * 在重新赋值这方面上也不同：指针的指向可以被改变。但是引用一旦初始化为执行一个对象后，就不能再被改变了。

### 左值引用和右值引用
1. 左值引用
    左值引用是对一个对象的持久身份的引用。在C++中，左值引用通常表示的是可以在等号左边出现的值的引用。这种引用常用于函数中参数的传递，避免函数调用过程中出现不必要的大对象的复制操作，这复制过程通常非常耗时。左值引用的特点就是不能绑定在字面量（1，2等数字）和临时对象（一个函数的返回值）上。
2. 右值引用
    右值引用就是对一个对象临时身份的引用，他指的是可以在等号右边出现的值但是不能在等号的左边出现。这种引用常用语引用临时对象，如函数的返回值，减少不必要的赋值构造，从而优化性能。
    * 如何将一个左值转换为右值呢？
        通过C++的std::move函数即可

### 完美转发
C++的完美转发指的是，在函数模版中，能够以参数原本的类型（左值或者右值）进行传递并且转发到另一个函数的能力，这个主要通过std::forward函数进行实现。其中涉及到了C++的引用折叠的规则。
* 引用折叠
    在C++中存在的引用折叠的规则，简单来说就是允许一个类型的右值引用折叠成左值或者保持右值的一种特性，举个例子来说，假如我有一个函数的参数是`int&&`，当我给这个函数传入的是一个左值引用的时候，此时这个类型就会变成`int&& &`，随后C++就会对这个类型的引用进行折叠，实际就是减去2个&符号，因为我们原来由三个&符号，减去两个后就只剩下一个，表示的就是左值引用，而如果我们是传入右值引用，那么4个&符号就会减去2个&符号，剩下两个，保持了右值引用的类型，此时我们就保证了参数的传入是保持了它本身的引用状态。

## 数据结构算法

### 红黑树和AVL树

### C++ sort的实现，时间复杂度，空间复杂度
 

### 洗牌算法
1. 最简单粗暴的洗牌方法，每一轮都生成一对随机数，交换随机数位置的牌
    ```cpp
    std::random_device rd;  // 种子
    std::mt19937 gen(rd()); // 生成引擎
    std::uniform_int_distribution<> distrib(1, suit.size());
    for(int i = 0; i < suit.size(); i++) {
        int random1 = distrib(gen);
        int random2 = distrib(gen);
        std::swap(suit[random1], suit[random2]);
    }
    ```
    这个算法虽然能在某种程度上实现洗牌，但是效果不够好，没有很好的照顾到suit中的每一张牌，同时，如果两次生成的random1和random2相同，也会导致洗牌次数的浪费。

2. Fisher–Yates Shuffle算法
    ```cpp
    std::random_device rd;  // 种子
    std::mt19937 gen(rd()); // 生成引擎
    vector<int> res;
    for(int i = suit.size() - 1; i > 0; i--)
    {
        std::uniform_int_distribution<> distrib(1, i);
        int random1 = distrib(gen);     // 生成[1, i]的随机数
        res.push_back(suit[random1]);   // 向结果集中插入新数字
        suit.erase(suit.begin() + random1);
    }
    ```
    这个算法在完成一次洗牌动作之后就会缩小下一次的洗牌范围，充分的照顾到了每一张牌，并且解决了暴力法中两次random1和random2相同的可能性，使最终洗牌得到的结构一直保持在$n!$


3. Knuth-Durstenfeld Shuffle算法
    ```cpp
    std::random_device rd;  // 种子
    std::mt19937 gen(rd()); // 生成引擎
    for(int i = suit.size() - 1; i > 0; i--)
    {
        std::uniform_int_distribution<> distrib(1, i);
        int random1 = distrib(gen);     // 生成[1, i]的随机数
        std::swap(suit[random1], suit[i]);  // 交换对应两个位置的牌
    }
    ```
    这个算法是上一个算法的改进，通过原地调换位置的方式，使得空间复杂度从上方的O(n)降低至O(1)

### 寻路算法
1. 深度优先(DFS)
    深度优先搜索是盲目式(意味着不知道终点在哪里的)的寻路算法，并且除非我们把所有可能的路径都走完了，否则DFS给我们的路径通常不是最优解。

2. 广度优先(BFS)
    广度优先搜索同样是盲目式的(意味着不知道终点在哪里的)的寻路算法，但是BFS总是能给我们最优解。

3. 迪杰斯特拉算法
    Dijsktra算法是BFS的改进，在BFS中，所有点的访问顺序都是认为规定好的，比如一个固定的顺序上右下左，但是在Dijsktra算法中，每一次选择下一步都是选择当前记录的累计成本最小的节点。因此在Dijsktra算法中我们需要每一次都遍历一次cost数组找到当前开销最小的点，或者说维护一个优先队列。
    同样的，Dijsktra算法也是盲目式(意味着不知道终点在哪里的)的算法。

4. A*算法

### topK问题
1. 优先队列
    使用优先队列维护当前最大的K个数

2. MapReduce
    例如说存在10个1g的文件，统计出这是个文件里面最高频的10个词，内存一次最多只能容纳下一个文件。
    解决方法：通过每一次读取一个文件，统计当前文件中最高频的十个词，这样在完成10次后，我们需要的就是在剩下的100个词中进行去重、取得频率Top10的单词。

当数据量特别大的时候，需要主要读取文件要用流式读取，避免文件比内存当无法读进。比如C++ std::fstream

## Unreal Engine 相关

### UE反射系统

### UE垃圾回收

### UE渲染流程

## 图形学相关

### 渲染管线

### PBR和BRDF

## 操作系统相关

### 线程和进程的区别
1. 什么是进程
    进程是计算机执行的基本单位
    进程是资源分配的基本单位，包括的资源有：
    * 一段独立的内存地址，包括代码段，数据段和堆栈
    * 一系列的操作系统资源是按照进程为单位分配的，包括文件句柄，网络连接等

    虽然进程能很好的完成我们的任务，但是在如今的多核CPU中，创建进程和切换进程的开销非常大，首先第一个问题就是每一次切换进程都需要操作系统进行一次上下文切换，虽然这对于现代CPU并不会造成什么压力，但是对于内存和IO这种比较慢速的硬件来说却是一个瓶颈；其次创建进程也需要操作系统为其分配一段新的、独立的内存和操作系统资源；同时进程和进程的通信开销非常的大，对于需要执行同一项任务的两个进程之间难以进行通信，进程间的通信主要通过：管道、消息队列、共享内存或者socket套接字等。
    因此，线程就诞生了

2. 什么是线程
    在出现线程后，内核级线程就成为了CPU调度的基本单位了。
    相比于进程，线程仅仅只维护自己的一个堆栈，用于分配资源，以及寄存器的状态，用于线程切换。其余的诸如代码段，数据段以及操作系统资源如文件句柄等与其他在同一个进程中的其他线程共享。
    此时，如果我们切换线程而非进程时，切换的开销就大大降低了，尤其是对于用户级线程而言，甚至不需要进行上下文切换。
    同时线程的通信主要通过共享内存的方式，因为同属于一个进程的线程是共享同一段代码的。

3. 进程和线程的区别
    * 从创建和开销方面来讲：
        创建和销毁进程通常会消耗更多的时间，因为需要操作系统为其分配独立的内存和IO等资源。
        创建和销毁线程的开销则是要小很多，因为一个线程需要维护的仅仅只有其CPU状态：如寄存器状态，栈的位置等。
    * 从独立性上面来讲：
        进程的独立性更好，一个进程的崩溃不会影响到另一个进程
        线程的独立性较差，一个线程的崩溃很可能会影响到另一个线程
    * 从通信机制上来讲：
        进程通常需要使用管道、消息队列、共享内存、socket套接字的方式进行通信，并且一定伴随着进程的上下文切换，这意味着需要一次从用户状态切换到内核状态，开销非常大。
        线程的通信只需要通过共享内存即可，因为同属于同一个进程的线程共享了同一段虚拟内存。就算是使用内核级线程，切换的开销也没有进程大，如果我们使用的是内核级线程，开销就更加小了，甚至不需要操作系统进行模式切换。

### 死锁的形成条件
1. 互斥条件：至少有一个资源必须处于非共享模式，即如果是多个线程想要同时访问，他们只能一个个排队进行访问。
2. 持有并等待条件：一个进程必须至少持有一个资源并等待另一个资源，而这个资源又被另一个进程持有
3. 非抢占条件：资源不能被强制从进程中夺取
4. 循环等待条件：必须存在一个进程等待循环，比如进程A等待进程B的资源，同时进程B等待进程A的资源，此时就会形成一个环。

### 如何解决死锁
1. 提前预防：通过打破死锁形成的四个条件之一，就不会再产生死锁了，比如：所有进程或者说线程，只能通过特定的顺序进行获取资源，比如有A、B、C三个资源，设定所有线程必须以B、A、C的顺序进行获取，这时如果所有线程都能按照约定俗成的顺序进行获取，就不会再产生死锁了。
2. 死锁避免：银行家算法
3. 死锁检测与恢复：在死锁已经发生的前提下，通过检测算法进行检测，发现死锁后使用终止或者回滚的方式进行解决。
4. 使用无死锁设计：比如不要通过共享内存的方式，而是通过消息传递的形式进行通信，从而避免死锁

### CPU调度算法

## 设计模式

## 计算机网络

### 7层模型
从底到顶总共7层模型分别是：
1. 物理层
    这一层用于处理电器或者物理接口相关的细节，包括传输数据的媒介
    设备包括：电路、光纤、集线器等
2. 数据链路层
    这一层负责在相邻节点之间建立、维护与终止等功能。
    设备包括：交换机、网桥等
    协议包括：Ethernet(以太网协议)、PPP(点对点协议)
3. 网络层
    这一层用于处理分组在网络中的活动，比如如何选择下一个路由等。
    设备包括：路由器
    协议包括：IP协议
4. 传输层
    这一层负责提供端到端的数据传输，在OSI的模型中，传输层负责保证数据的完整性和可靠性。
    协议包括：TCP(传输控制协议)、UDP(用户数据协议)
5. 会话层
    这一层负责管理会话的建立、维护和终止等功能。
6. 表示层
    这一层确保从一个节点发送到另一个节点的数据能被应用层读取和理解，可以涉及到数据加密、数据格式化等功能。
7. 应用层
    这一层负责为应用软件提供网络服务。
    协议包括HTTP、FTP、SMTP

### TCP的三次握手和四次挥手
首先来看看TCP报文的头部信息
![](https://pic2.zhimg.com/v2-6aabceb72ad215bf3abf465cbf31a16d_r.jpg)
其中的序号在下方会被表示为seq，而确认号会被表示为ack

1. 三次握手
    1. 发送端往接收端发送一个报文，这个报文中的**SYN = 1，ACK = 0，seq = x**，表示这是一个请求连接报文。
    2. 若是接收端同意同意连接，就会返回一个报文，这个报文中的**SYN = 1，ACK = 1，ack = x + 1，seq = y**，表示这是一个接收连接报文。
    3. 此时连接的发起方收到接受连接报文，就会再次返回一个报文，在这个报文中**SYN = 1，ACK = 1，ack = y + 1，seq = x + 1**。

    *  **为什么不采用两次握手？**
        假如A发送了一次请求连接报文，但是这个报文因为堵塞迟迟没有到B，因此A认为这个连接已经丢失了，就再发出了一个请求，此时第一个报文的堵塞问题消失了并且正确的送到了B中，此时B会认为A请求了两次连接，如果我们没有第三次从请求放发送到被请求方的报文，A和B之间就会建立起两个连接。
    * **为什么不需要四次握手？**
        三次就可以确认连接已经正确确立。使用四次会浪费资源。

2. 四次挥手
    1. 客户端发送报文，这个报文的FIN = 1，意味着这是一个终止连接报文
    2. 此时服务器收到这个终止连接报文，返回一个ACK = 1的报文表示确认终止
    3. 等到服务器处理完成数据后，向客户端发送一个FIN = 1的报文，这同样是一个终止连接的报文
    4. 此时客户端收到服务器的终止连接报文，向服务器发送一个ACK = 1的报文表示确认终止。

    * **为什么需要四次？**
        这是由于TCP连接具有半关闭的特性。TCP在一方结束连接后只是不能再继续发送数据，**但仍保留了接收对方数据的能力**所以两次挥手能关闭整个连接的一半，彻底关闭双方的连接需要4次。
        举个例子：就好像是两个人说话，A对B说，我已经没有话要说了，但是A仍然能接收B所说的话，只是A不会再说话了而已，只有当B也说“我已经没有话要说了”时，这个对话才算是完整结束。

### TCP和UDP的区别
1. 从连接角度来讲
    TCP是面相连接的协议，在传输数据之前需要客户端和服务器先建立连接
    UDP是一种无连接协议，数据可以在没有预先的进行连接的情况在发送数据。
2. 从可靠性来讲
    TCP由于是需要首先建立连接再发送数据的，因此TCP能保证数据能以正确的顺序被接收方所接收，并且提供了一些纠错的机制帮助接收方能辨别这个数据包是否正确。
    UDP由于是不需要建立连接而直接发送数据的，因此发送的数据可能会乱序到达，且没有机制能保证数据在网络传输的过程中没有发生错误等。
3. 从速度和效率方面讲
    由于TCP需要首先建立连接、确认和重传，因此效率比较低。
    而UDP不需要保证数据的正确性，且不需要建立连接，因此效率比较高。
4. 从数据流的类型上来讲
    TCP所传输的数据是字节流
    而UDP所传输的数据是消息，每一个发送的UDP数据报都是独立的消息。
5. 从两种不同协议的头部消息大小来说
    TCP需要20个字节，因为需要包含更多的控制信息，
    UDP只需要8个字节，因为这些控制信息比较少。
6. 从流量控制和拥塞控制方面来说
    TCP提供流量控制和拥塞控制机制
    UDP则不提供

### TCP的拥塞控制

### UDP如何实现可靠

